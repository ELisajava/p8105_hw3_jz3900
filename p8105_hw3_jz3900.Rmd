---
title: "p8105_hw3_jz3900"
author: "ELisajava"
date: "2024-10-15"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load Necessary Libraries
```{r}
library(tidyverse) 
library(ggplot2)
library(lubridate)
library(ggridges)
library(patchwork) #For combining plots
library(hexbin) #For hexbin plots
library(gt)
library(p8105.datasets)
```

# Configure Global Plot Settings
```{r}
knitr::opts_chunk$set(
  fig.width = 10,
  fig.asp = 0.8,
  out.width = '90%'
)

## Setting color options globally
options(
  ggplot2.continuous.color = "magma",
  ggplot2.continuous.fill = "magma"
)

## Assigning scales for discrete color and fill
discrete_color_scale <- scale_color_viridis_d
discrete_fill_scale <- scale_fill_viridis_d
```

# Problem 1
* Write a short description of the dataset.
* Clean the data. Create separate variables for year, month, and day. Ensure observations for temperature, precipitation, and snowfall are given in reasonable units.
* Make a two-panel plot showing the average max temperature in January and in July in each station across years.
* Make a two-panel plot showing (i) tmax vs tmin for the full dataset; (ii) make a plot showing the distribution of snowfall values greater than 0 and less than 100 separately by year.

## Step 1: Import and describe the dataset
```{r}
# Load the dataset
data("ny_noaa")

# Display the structure of the dataset
str(ny_noaa)

# Display the dimensions of the dataset
dim(ny_noaa)

# Summarize the dataset
summary(ny_noaa)
```
### A short description of the dataset

* The ny_noaa dataset have 2595176 columns (observations) and 7 columns (variables). 
* The variables includes: 
  * id: Weather station identifier,
  * date: Date of the observation,
  * prcp: Precipitation (tenths of mm),
  * snow: Snowfall (mm),
  * snwd: Snow depth (mm),
  * tmax: Maximum temperature (tenths of degrees C),
  * tmin: Minimum temperature (tenths of degrees C).
* Information on statistics：
  * prcp: Mean: 29.82, Min: 0.00, Max: 22860.00; 
  * snow: Mean: 5, Min: -13, Max: 10160; 
  * snwd: Mean 37.3, Min: 0.0, Max: 9195.0. 
* Note: Some variables contain missing values.

## Step 2: Missing data
```{r}
# Caculate the missing data percentages
ny_noaa %>%
  summarise(
    missing_prcp = mean(is.na(prcp)) * 100,
    missing_snow = mean(is.na(snow)) * 100,
    missing_snwd = mean(is.na(snwd)) * 100,
    missing_tmax = mean(is.na(tmax)) * 100,
    missing_tmin = mean(is.na(tmin)) * 100
  )

```
### Description of missing data:
  * Approximately 5.62% of the prcp values are missing, 
  * Approximately 14.68% of the snow values are missing,
  * Approximately 22.80% of the snwd values are missing, 
  * Approximately 43.69% of the tmax values and 46.23% of the tmin values are missing. The proportion of missing data for both tmax and tmin is notably high.

## Step 3: Data cleaning
```{r}
# Create separate variables for year, month, and day
ny_noaa = ny_noaa %>%
  mutate(
    year = year(date),
    month = month(date),
    day = day(date)
  )

# Convert `prcp`, `tmax`, and `tmin` to numeric format before unit conversion
ny_noaa = ny_noaa %>%
  mutate(
    prcp = as.numeric(prcp),
    tmax = as.numeric(tmax),
    tmin = as.numeric(tmin)
  )

# Adjust units for temperature and precipitation
ny_noaa = ny_noaa %>%
  mutate(
    prcp = prcp/10,  # Precipitation converts from tenths of mm to mm.
    tmax = tmax/10,  # Max temp converts from tenths of degrees Celsius to degrees Celsius.
    tmin = tmin/10   # Min temp converts from tenths of degrees Celsius to degrees Celsius.
  )

```{r}
# Ensure logical consistency in temperature data (tmax data is higher than tmin data)
ny_noaa = ny_noaa %>%
  filter(tmax > tmin | is.na(tmax) | is.na(tmin))  

# Filter rows with missing values in key variables (snow, snwd, tmax, tmin, prcp)
ny_noaa = ny_noaa %>%
  filter(!(is.na(snow) & is.na(snwd) & is.na(tmax) & is.na(tmin) & is.na(prcp)))
head(ny_noaa)
```

### Q 1: For snowfall, what are the most commonly observed values? Why?
```{r}
# Count the occurrences of each snowfall value
snow_counts = ny_noaa %>%
  count(snow) %>%
  arrange(desc(n))

# Display the most common snowfall values
head(snow_counts)
str(ny_noaa)
```

* Answer of Q 1:
  * The most commonly observed value for snowfall is 0 mm, with 2,008,508 occurrences.
  * A possible reason for this is that snowfall does not occur daily and is primarily concentrated in the winter months.

## Step 4: Data Visualization:
## Part 1: Average Max Temperature in January and July Across Years
```{r}
# Filter data for January and July
temp_jan_jul = ny_noaa %>%
  filter(month %in% c(1, 7)) %>%
  group_by(id, year, month) %>%
  summarise(
    avg_tmax = mean(tmax, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(month = case_when(
    month == 1 ~ "January",
    month == 7 ~ "July"
  ))

# Visualization for January
plot_jan <- ggplot(subset(temp_jan_jul, month == "January"), 
                   aes(x = year, y = avg_tmax, group = id, col = id)) +
  geom_point(alpha = 0.5) +
  labs(
    title = "Average Max Temperature in January",
    x = "Year",
    y = "Average Max Temperature (°C)"
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.title = element_text(hjust = 0.5,size=15)
)

# Visualization for July
plot_jul <- ggplot(subset(temp_jan_jul, month == "July"), 
                   aes(x = year, y = avg_tmax, group = id, col = id)) +
  geom_point(alpha = 0.5) +
  labs(
    title = "Average Max Temperature in July",
    x = "Year",
    y = "Average Max Temperature (°C)"
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.title = element_text(hjust = 0.5,size=15)
)

# Combine the two plots using patchwork library
combined_plot <- plot_jan / plot_jul
combined_plot + plot_layout(heights = c(1, 1))
```

### Q 2: Is there any observable / interpretable structure? Any outliers?

* Structure:

  * Temperature Separation: January temperatures are colder, ranging approximately from -10°C to 10°C, while July temperatures are much warmer, around 20°C to 35°C.
  * Variation: January shows more variation across years, with temperatures fluctuating widely. July has a more stable temperature range, with most values clustered between 25°C and 30°C.
  
* Trend: 

  * A slight upward trend in January’s temperatures is visible over time, while July’s temperatures remain largely stable.

* Outliers:

  * January: A few years have unusually cold temperatures, dipping below -10°C, which stand out as extreme values.
  * July: There are some outliers below 20°C, indicating unusually cool summers in certain years.

## Part 2: tmax vs tmin Plot and Snowfall Distribution
### tmax vs tmin Plot
```{r}
# Hexbin plot for tmax vs tmin
p_temp = ggplot(ny_noaa, aes(x = tmin, y = tmax)) +
  geom_hex(bins = 50) +
  labs(
    title = "Relationship Between Minimum and Maximum Temperatures",
    x = "Minimum Temperature (°C)",
    y = "Maximum Temperature (°C)"
  ) +
  theme_minimal()+
  theme(
     plot.title = element_text(hjust = 0.5,size=15)
  )
```

### Snowfall Distribution by Year
```{r}
### Snowfall Distribution by Year
# Filter snowfall data
snowfall_filtered = ny_noaa %>%
  filter(snow > 0, snow < 100)

# Plot snowfall distribution by year using boxplots
p_snow = ggplot(snowfall_filtered, aes(x = factor(year), y = snow)) +
  geom_boxplot(outlier.size = 0.5, alpha = 0.7) +
  labs(
    title = "Distribution of Snowfall by Year",
    x = "Year",
    y = "Snowfall (mm)"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1),
    panel.grid.major.x = element_blank(),
    plot.title = element_text(hjust = 0.5,size=15) 
  )

# Fix: ensure correct color scale for hex plot
p_temp = p_temp + scale_fill_viridis_c(option = "magma")

# Combine the temperature and snowfall plots
p_temp + p_snow + plot_layout(ncol = 1)
```

# Problem 2

* Load, tidy, merge, and organize the data sets: (1) include all originally observed variables); (2) exclude participants less than 21 years of age; (3) exclude those with missing demographic data; (4) encode data with reasonable variable classes (i.e. not numeric, and using factors with the ordering of tables and plots in mind).

* Produce a reader-friendly table for the number of men and women in each education category, and create a visualization of the age distributions for men and women in each education category. Comment on these items.

* Using the tidied dataset, aggregate across minutes to create a total activity variable for each participant. Plot these total activities (y-axis) against age (x-axis); your plot should compare men to women and have separate panels for each education level. Include a trend line or a smooth to illustrate differences. Comment on your plot.

* Make a three-panel plot that shows the 24-hour activity time courses for each education level and use color to indicate sex. Describe in words any patterns or conclusions you can make based on this graph; including smooth trends may help identify differences.

## Step 1: Load and Organize the Data Sets
```{r}
# Load the data sets
demographics <- read.csv(file = "./dataset/nhanes_covar.csv", skip = 4)
accelerometer <- read.csv(file = "./dataset/nhanes_accel.csv")

# Check structure and summary of both data sets
str(demographics)
summary(demographics)

str(accelerometer)
summary(accelerometer)

# Filter out participants younger than 21 years old and remove missing data in the demographic dataset
demographics <- demographics %>%
  filter(age >= 21) %>%
  drop_na()

# Merge the two datasets by SEQN
data <- inner_join(accelerometer, demographics, by = "SEQN") %>%
  pivot_longer(
    cols = starts_with("min"),
    names_to = "minute_interval",
    values_to = "MIMS"
  ) %>%
  mutate(
    sex = factor(sex, levels = c(1, 2), labels = c("male", "female")),
    education = factor(education, levels = c(1, 2, 3), labels = c("Less than high school", "High school equivalent", "More than high school")),
    minute_interval = str_replace(minute_interval, "min", "")
  )
```
* I merged the datasets and excluded participants who were younger than 21 years old or had missing demographic information. I transformed the variables for sex and education into categorical factors, assigning the labels "male" and "female" for sex, and "Less than high school," "High school equivalent," and "More than high school" for education. Additionally, I stripped the "min" strings from the minute_interval variable.

## Step 2: Creat a readable table
```{r}
# Select distinct participant data based on SEQN, sex, and education
participant_data <- data %>%
  select(SEQN, sex, education) %>%
  distinct()

# Summarize participant count by sex and education
num_data <- participant_data %>%
  group_by(sex, education) %>%
  summarise(number = n(), .groups = "drop")

# Reshape the data for better readability
readable_data <- num_data %>%
  pivot_wider(
    names_from = education,
    values_from = number
  )

# Create a more readable table
readable_data%>%
  gt() %>%
  tab_header(title = "Number of Men and Women in Each Education Category")

# Create a bar plot of participant counts
p1 <- ggplot(num_data, aes(x = education, y = number, fill = sex)) +
  geom_col(position = position_dodge2()) +
  geom_text(aes(label = number), position = position_dodge2(width = 0.9), vjust = -0.5) +
  theme_minimal() +
  labs(title = "Number of Participants by Sex and Education", x = "Education Level", y = "Count of Participants") +
  theme(axis.text.x = element_text(angle = 30, hjust = 0.75),
        plot.title = element_text(hjust = 0.5,size=15)
        )

# Create a proportional bar plot by education level and sex
p2 <- ggplot(participant_data, aes(x = education, fill = sex)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_minimal() +
  labs(title = "Proportion of Sex within Education Level", x = "Education Level", y = "Proportion") +
  theme(axis.text.x = element_text(angle = 30, hjust = 0.75),
        plot.title = element_text(hjust = 0.5,size=15)
        )

# Combine the two plots side by side
combined_plot <- p1 + p2 + plot_layout(ncol = 2)
combined_plot
```


* I started by generating a table that shows the count of men and women across various education levels. To enhance readability, I reformatted the table using the `pivot_wider` function. The resulting plot indicates that individuals with more than a high school education make up the largest proportion for both sexes. Moreover, there are fewer men than women in the "Less than high school" category, while more men than women fall into the "High school equivalent" category.

## Step 3: Aggregate Total Activity
```{r}
# Summarize total activity for each participant
total_activity_data <- data %>%
  group_by(SEQN, sex, age, education) %>%
  summarise(total_activity = sum(MIMS, na.rm = TRUE), .groups = "drop")

# Plot total activity vs age by sex, with separate panels for education levels
total_activity_plot <- ggplot(total_activity_data, aes(x = age, y = total_activity, color = sex)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "loess", se = FALSE) +
  facet_wrap(~ education) +
  labs(title = "Total Activity vs Age by Sex and Education Level", x = "Age", y = "Total Activity (MIMS)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 0.75),
        plot.title = element_text(hjust = 0.5,size=15)  
  )

# Display the plot
print(total_activity_plot)
```

* In the graph, male data is shown in red and female data in blue. Overall, women's total activity levels are higher than men's across all ages in the two right-hand graphs. In the left graph, women's total activity exceeds men's until around age 40, after which it falls below men's. In terms of overall trends, total activity decreases for all education levels after around age 60. Those with less than a high school education reach their highest activity levels around age 20, while individuals with a high school equivalent education peak around age 40. People with more than a high school education maintain relatively high activity levels up to age 60.

## Step 4: Create a three-panel plot
```{r}
# Function to generate activity plots with refinements
generate_activity_plot <- function(education_category, plot_title) {
  activity_data <- data %>%
    filter(education == education_category) %>%
    mutate(hour_interval = as.numeric(minute_interval) %/% 60) %>%  # Grouping by hour
    group_by(hour_interval, sex) %>%  # Group by hour and sex
    summarise(mean_activity_per_hour = mean(MIMS, na.rm = TRUE), .groups = "drop")
  
  ggplot(activity_data, aes(x = hour_interval, y = mean_activity_per_hour, color = sex)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "loess", se = FALSE) +
    theme_minimal() +
    theme(
      legend.position = "bottom",
      plot.title = element_text(hjust = 0.5,size=15)  # Centering the title
    ) +
    labs(
      title = plot_title,
      x = "Hour Interval",
      y = "Mean MIMS per Hour"
    )
}

# Generate plots for different education levels
p1 <- generate_activity_plot("Less than high school", "Less than High School")
p2 <- generate_activity_plot("High school equivalent", "High School Equivalent")
p3 <- generate_activity_plot("More than high school", "More than High School")

# Combine the plots
p1 + p2 + p3
``` 

* The plot shows clear differences in daily physical activity patterns by education level and gender. Activity generally peaks around midday for all groups, likely due to routines like commuting, work, or exercise. Those with higher education levels maintain more structured and higher activity throughout the day, suggesting better health awareness or access to physical activities. Women tend to have higher activity levels than men, especially in the "High School Equivalent" and "More than High School" groups, indicating more involvement in organized activities. In contrast, those with less than a high school education show lower activity peaks, possibly due to more sedentary behavior. Activity levels decrease sharply in the evening, likely reflecting rest periods. These insights highlight the need for strategies to promote physical activity, especially among those with lower education levels and in the evening to reduce sedentary time.

# Problem 3
## Step 1:Import and organize the dataset
### Import four datasets
```{r}
Jan_2020_Citi <- read_csv("./dataset/citibike/Jan\ 2020\ Citi.csv", show_col_types = FALSE)
Jan_2024_Citi <- read_csv("./dataset/citibike/Jan\ 2024\ Citi.csv", show_col_types = FALSE)
July_2020_Citi <- read_csv("./dataset/citibike/July\ 2020\ Citi.csv", show_col_types = FALSE)
July_2024_Citi <- read_csv("./dataset/citibike/July\ 2024\ Citi.csv", show_col_types = FALSE) 
```

### Clean and tidy these data
```{r}
# Add year, month and dataset source columns to each dataset 
Jan_2020_Citi <- Jan_2020_Citi %>% 
  mutate(year = 2020, month = "January", dataset = "Jan_2020_Citi")
Jan_2024_Citi <- Jan_2024_Citi %>% 
  mutate(year = 2024, month = "January", dataset = "Jan_2024_Citi")
July_2020_Citi <- July_2020_Citi %>% 
  mutate(year = 2020, month = "July", dataset = "July_2020_Citi")
July_2024_Citi <- July_2024_Citi %>% 
  mutate(year = 2024, month = "July", dataset = "July_2024_Citi")

# Merge four datasets 
citi_data <- bind_rows(Jan_2020_Citi, Jan_2024_Citi,July_2020_Citi, July_2024_Citi) 

# Display the merged data
glimpse(citi_data)

# Check missing data
colSums(is.na(citi_data))
```
* I merged the four datasets into a single data frame and checked for missing values. The dataset is generally complete, with the exception of some missing station names. These missing values may be due to technical issues, such as GPS errors, or data entry problems. To address this, I label the missing station names as 'Unknown' in next code. 

```{r}
## Lable missing station names as 'Unknown'
citi_data <- citi_data %>%
  mutate(
    start_station_name = ifelse(is.na(start_station_name), "Unknown", start_station_name),
    end_station_name = ifelse(is.na(end_station_name), "Unknown", end_station_name)
  )

## Check for missing data again
colSums(is.na(citi_data))

## Remove duplicate rows
citi_data <- citi_data %>%
  distinct()

## Check for and remove abnormal riding duration
citi_data <- citi_data %>%
  filter(duration >= 0) 

# rearrange the column sequence for readability
citi_data <- citi_data %>%
  select(
    ride_id, member_casual, rideable_type, year, month, weekdays, duration, start_station_name, end_station_name, dataset)

# Display the resulting dataset
glimpse(citi_data)
```
### Description of the resulting dataset:
* This dataset contains information on Citi Bike rides taken in New York City during January and July of 2020 and 2024.
* The key columns (variables) include:
  * ride_id: Unique identifier for each ride.
  * member_casual: Rider type, either member or casual riders.
  * rideable_type: Type of bike, either classic_bike or electric_bike.
  * year: Year of the ride.
  * month: month of the ride.
  * weekdays: weekdays of the ride.
  * duration: Ride duration in minutes.
  * start_station_name: Starting stations name.
  * end_station_name: ending stations name.
  * dataset: Indicates the dataset source (e.g., Jan_2020_Citi).
* This dataset is prepared for analyzing ridership trends, user behavior, and ride patterns across various time periods and rider types.

## Step 2: Produce a reader-friendly table
```{r}
# Summarize total rides by year, month, and rider type
summary_table <- citi_data %>% 
  group_by(year, month, member_casual) %>% 
  summarise(total_rides = n(), .groups = "drop")

# Pivot the table to have rider types as columns
pivoted_table <- summary_table %>% 
  pivot_wider(names_from = member_casual, values_from = total_rides, names_prefix = "Total_") %>% 
  mutate(Total_Rides = Total_member + Total_casual)  # Calculate sum of member and casual rides

# Create a reader-friendly table with gt()
pivoted_table %>% 
  gt() %>% 
  tab_header(title = "Total Number of Rides by Year, Month, and Rider Type", 
             subtitle = "Citi Bike Member vs Casual Riders") %>% 
  cols_label(
    year = "Year", 
    month = "Month", 
    Total_member = "Member Total Rides", 
    Total_casual = "Casual Total Rides",
    Total_Rides = "Total Rides"
  ) %>% 
   fmt_number(columns = c(Total_member, Total_casual, Total_Rides))%>% 
   tab_options(
    heading.align = "center"  # Center-align the title and subtitle
  )
```

### Comment on these results:
The table now features a 'Total Rides; column, making it easy to view the combined ride totals for both members and casual riders across each time period. This layout highlights overall ridership trends while still offering a clear breakdown between the two rider types.

 * Casual vs. Member Rides:  
Members consistently take a higher number of rides compared to casual    riders, which aligns with the understanding that members are frequent, regular users, while casual riders are typically occasional users or tourists.

 * Seasonality:  
There is a noticeable increase in rides in July compared to January for both years, which suggests seasonal usage patterns. This likely reflects the fact that summer months see higher ridership due to favorable weather. 

 * Year-over-Year Growth:  
When comparing 2020 to 2024, we see an increase in the total number of rides in both January and July. This suggests overall growth in Citi Bike usage over the four-year period.

## Step 3: Create a table of the 5 most popular starting stations in July 2024.
### Find the 5 most popular starting stations
```{r}
# Filter the data for July 2024
july_2024_data <- citi_data %>% 
  filter(year == 2024, month == "July")

# Find the 5 most popular starting stations
popular_stations <- july_2024_data %>% 
  group_by(start_station_name) %>%  # Group the data by start_station_name
  summarise(total_rides = n()) %>%  # Count the number of rides originating from each station
  arrange(desc(total_rides)) %>%  # Sort stations in descending order of the total number of rides
  slice_head(n = 5)  # Selects the top 5 starting stations

# Show the 5 most popular stations
cat("The 5 most popular starting stations are", 
    paste(popular_stations %>% pull(start_station_name), collapse = ", "), "\n")
```

* The 5 most popular starting stations are:
1. Pier 61 at Chelsea Piers,
2. University Pl & E 14 St,
3. W 21 St & 6 Ave
4. West St & Chambers St
5. W 31 St & 7 Ave

### Display this result in a table
```{r}
popular_stations %>% 
  gt() %>% 
  tab_header(title = "Top 5 Starting Stations for July 2024",
             subtitle = "Based on Number of Rides"
) %>% 
  tab_options(
    heading.align = "center"  # Center-align the title and subtitle
  )
```

### Comment on this table:
* Most of the top stations are located in busy, popular areas of Manhattan, serving as hubs for both commuters and tourists. 

* The small difference in ride numbers between stations shows that all are heavily used. 

* Chelsea Piers stands out as a major attraction, making it the most popular station.

## Step 4: Make a plot to investigate the effects of day of the week, month, and year on median ride duration.
### Calculate median ride duration
```{r}
# Calculate the median ride duration for each combination of year, month, and weekday
median_duration_data <- citi_data %>% 
  group_by(year, month, weekdays) %>% 
  summarise(median_duration = median(duration), .groups = "drop") %>% 
  mutate(year = as.factor(year), 
         weekdays = factor(
           weekdays, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")))

# Create a multi-panel plot to show the influence from these factors on the median ride duration.
ggplot(median_duration_data, aes(x = weekdays, y = median_duration, fill = factor(year))) +
  geom_bar(stat = "identity", position = "dodge", alpha = 0.8) +  # Side-by-side bars (dodge)
  geom_line(aes(group = year, color = factor(year)), size = 1.0, position = position_dodge(width = 0.9)) +  # Add line trend on top of bars
  facet_wrap(~ month, ncol = 2) +  # Create two panels for January and July
  labs(title = "Comparison of Median Ride Duration in January and July (2020 vs 2024)",
       x = "Day of the Week",
       y = "Median Ride Duration (minutes)",
       fill = "Year", color = "Year") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5,size=15) 
  )
```

### Comment on the observations from this plot:
* Seasonal Differences:
July has longer median ride durations than January, likely due to favorable summer weather encouraging extended rides.

* Weekday vs. Weekend:
Ride durations are notably higher on weekends (Saturday and Sunday) compared to weekdays, indicating longer, possibly more leisurely rides on weekends.

* Comparison between 2020 and 2024:
In January, the median ride durations are quite similar for both years. However, in July, rides were longer in 2020, particularly on weekends, which could point to changes in rider behavior influenced by external factors.

Conclusion:
The data highlights clear seasonal and weekly patterns, with longer rides in July and over the weekends, especially in 2020 compared to 2024.

## Step 5: Make a figure that shows the impact of month, membership status, and bike type on the distribution of ride duration for data in 2024.
```{r}
# Select only the 2024 data
citi_data_2024 <- citi_data %>%
  filter(year == 2024)  # Filtering for the year 2024

# Generate the box plot to analyze the effects of month, membership type, and bike type
ggplot(citi_data_2024, aes(x = rideable_type, y = duration, fill = member_casual)) +
  geom_boxplot(alpha = 0.7, outlier.size = 1.2) +  # Display the box plot to show distribution
  facet_wrap(~ month, scales = "free", ncol = 2) +  # Split the plot by month
  labs(title = "Impact of Month, Membership Type, and Bike Type on Ride Duration (2024)",
       x = "Type of Bike",
       y = "Ride Duration (minutes)",
       fill = "Rider Type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), # Tilt the x-axis labels for readability
        plot.title = element_text(hjust = 0.5, size=15)
  )
```

### Comment on the results:
 * Effect of Bike Type:  
Electric bikes generally result in shorter ride times compared to classic bikes, which is expected since electric bikes allow for faster travel. This pattern holds true for both January and July. Casual riders, especially in July, tend to have slightly longer rides on electric bikes compared to members.

 * Seasonal Influence:  
In July, ride durations vary more widely than in January, likely because the warmer weather encourages longer, leisure-based rides. In contrast, January sees shorter rides, likely due to the colder temperatures limiting outdoor activity.

 * Membership Trends:  
Casual riders generally have longer ride durations than members, regardless of bike type, with the difference being especially pronounced for classic bikes. This suggests that casual users may be taking longer, more recreational trips, while members focus on shorter, more practical rides.

 * Ride Duration Patterns:  
The data shows more outliers (very long rides) among casual riders on classic bikes, especially in July. This suggests that some casual riders take much longer trips during the summer months.

Summary:  
Electric bikes lead to quicker, shorter rides, particularly for members, while casual riders tend to take longer rides, especially on classic bikes, with longer trips being more frequent during the summer month.
